<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.545">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Stijn Lievens">
<meta name="dcterms.date" content="2024-06-21">

<title>Home - Duplicate Detection</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo_cads_white.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Home</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.hogent.be/onderzoekscentra/cads"> <i class="bi bi-globe" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/hogent-cads/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/showcase/centre-for-applied-data-science/about/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Duplicate Detection</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">data cleaning</div>
                <div class="quarto-category">duplicate detection</div>
                <div class="quarto-category">fuzzy matching</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Stijn Lievens </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">June 21, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1</span> Introduction</a></li>
  <li><a href="#comparing-a-single-column" id="toc-comparing-a-single-column" class="nav-link" data-scroll-target="#comparing-a-single-column"><span class="header-section-number">2</span> Comparing a Single Column</a>
  <ul>
  <li><a href="#character-based-methods" id="toc-character-based-methods" class="nav-link" data-scroll-target="#character-based-methods"><span class="header-section-number">2.1</span> Character-based methods</a>
  <ul class="collapse">
  <li><a href="#edit-distance" id="toc-edit-distance" class="nav-link" data-scroll-target="#edit-distance"><span class="header-section-number">2.1.1</span> Edit distance</a></li>
  <li><a href="#affine-gap-distance" id="toc-affine-gap-distance" class="nav-link" data-scroll-target="#affine-gap-distance"><span class="header-section-number">2.1.2</span> Affine gap distance</a></li>
  <li><a href="#distance-based-on-n-grams" id="toc-distance-based-on-n-grams" class="nav-link" data-scroll-target="#distance-based-on-n-grams"><span class="header-section-number">2.1.3</span> Distance based on n-grams</a></li>
  </ul></li>
  <li><a href="#token-based-methods" id="toc-token-based-methods" class="nav-link" data-scroll-target="#token-based-methods"><span class="header-section-number">2.2</span> Token-based methods</a>
  <ul class="collapse">
  <li><a href="#method-based-on-atomic-strings" id="toc-method-based-on-atomic-strings" class="nav-link" data-scroll-target="#method-based-on-atomic-strings"><span class="header-section-number">2.2.1</span> Method based on “atomic strings”</a></li>
  <li><a href="#method-combining-n-grams-with-tf.idf" id="toc-method-combining-n-grams-with-tf.idf" class="nav-link" data-scroll-target="#method-combining-n-grams-with-tf.idf"><span class="header-section-number">2.2.2</span> Method combining n-grams with “tf.idf”</a></li>
  </ul></li>
  <li><a href="#phonetic-methods" id="toc-phonetic-methods" class="nav-link" data-scroll-target="#phonetic-methods"><span class="header-section-number">2.3</span> Phonetic Methods</a></li>
  <li><a href="#methods-based-on-word-semantics" id="toc-methods-based-on-word-semantics" class="nav-link" data-scroll-target="#methods-based-on-word-semantics"><span class="header-section-number">2.4</span> Methods Based on Word Semantics</a></li>
  </ul></li>
  <li><a href="#comparing-records" id="toc-comparing-records" class="nav-link" data-scroll-target="#comparing-records"><span class="header-section-number">3</span> Comparing Records</a>
  <ul>
  <li><a href="#limiting-the-number-of-record-comparisons" id="toc-limiting-the-number-of-record-comparisons" class="nav-link" data-scroll-target="#limiting-the-number-of-record-comparisons"><span class="header-section-number">3.1</span> Limiting the Number of Record Comparisons</a></li>
  </ul></li>
  <li><a href="#python-libraries-for-duplicate-detection" id="toc-python-libraries-for-duplicate-detection" class="nav-link" data-scroll-target="#python-libraries-for-duplicate-detection"><span class="header-section-number">4</span> Python Libraries for Duplicate Detection</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">5</span> Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>A common problem with master data is that different records refer to the same real world entity. This can occur, for example, when a customer was registered twice (once when first contacting the company and a second time when an order was actually placed), or when a product was created twice.</p>
<p>At first sight, discovering duplicates seems easy to solve: go through all record pairs and verify whether they are the same or not. In practice, however, this is much more difficult because duplicate records are often <strong>similar</strong> but <strong>not identical</strong>. The question is then to identify these similar record pairs.</p>
</section>
<section id="comparing-a-single-column" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Comparing a Single Column</h1>
<p>Before starting to compare entire records, it seems obvious to look into how to compare values in a single column. Here we assume that the values in a column are of “string” type. What one typically wants then is a <strong>similarity measure</strong> that indicates how similar two strings are. Such a similarity measure takes as input two strings and has as output a number indicating how similar the two strings are, where the value 1 usually stands for “perfectly similar” and the value 0 for “not at all similar”. Sometimes <strong>distance measures</strong> are used: with a distance measure, the meaning is exactly reversed: a distance equal to zero means that the strings are similar, and the larger the (value of the) distance the more different the strings are.</p>
<p>The various ways in which the similarity of (or distance between) two strings can be determined can be divided into a number of categories:</p>
<ul>
<li>Character-based methods</li>
<li>Token-based methods</li>
<li>Methods based on the pronunciation of the words/strings</li>
<li>Methods based on word semantics</li>
</ul>
<section id="character-based-methods" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="character-based-methods"><span class="header-section-number">2.1</span> Character-based methods</h2>
<p>As the name suggests, character-based methods work at the level of individual characters. These methods give good results when the cause of the errors is expected to be small typing errors, e.g.&nbsp;swapping two letters or accidentally adding a small number of characters. Within this category, we recognise the following distance measures:</p>
<ul>
<li><strong>Edit distance</strong>: this distance function is good at recognising small typographical errors.</li>
<li><strong>Affine gap distance</strong>: this distance function takes into account that once one has inserted an extra character one is likely to insert additional extra characters.</li>
<li><strong>Distance based on n-grams</strong>: this considers how many <span class="math inline">\(n\)</span>-grams two strings have in common, the intuition being that similar strings have many <span class="math inline">\(n\)</span>-grams in common but strings that differ a lot do not.</li>
</ul>
<p>Below we give a brief explanation of each of these 3 distance measures, along with additional references where you can find more detail.</p>
<section id="edit-distance" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="edit-distance"><span class="header-section-number">2.1.1</span> Edit distance</h3>
<p>The <a href="https://en.wikipedia.org/wiki/Levenshtein_distance">edit or Levenshtein distance</a> is the minimum number of substitutions, insertions and deletions required to convert two strings into each other. For example, the Levenshtein distance between “CADS” and “LAST” is equal to three.</p>
<pre><code>CADS (substitute C by L) -&gt; LADS (delete D) -&gt; LAS (insert T) -&gt; LAST</code></pre>
</section>
<section id="affine-gap-distance" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2" class="anchored" data-anchor-id="affine-gap-distance"><span class="header-section-number">2.1.2</span> Affine gap distance</h3>
<p>When strings were abbreviated or shortened, the edit distance sometimes shows a large value even though they are about the same entity. An example would be the strings “John R. Smith” and “Jonathan Richard Smith”. With the affine gap distance, one adjusts the Levenshtein distance by introducing two additional operations, namely “opening” a hole and “expanding” a hole, where typically opening a hole has a greater cost (i.e.&nbsp;will give rise to a greater distance) than expanding a hole. The reasoning is that once one has introduced an additional first character one might add several more.</p>
<p>By way of example we show the affine gap distance between the words “Boulevard” and “Blvd”.</p>
<pre><code>Boulevard (1 deletion) =&gt; Bulevard
Bulevard (0.5 subsequent deletetion) =&gt; "Blevard"
Blevard (1 deletion) =&gt; Blvard
Blvard (1 deletion) =&gt; Blvrd
Blvrd (0.5 subsequent deletion) =&gt; Blvd </code></pre>
<p>The affine gap distance between “Boulevard” and “Blvd” is 4 whereas the regular edit distance would yield a value of 5.</p>
</section>
<section id="distance-based-on-n-grams" class="level3" data-number="2.1.3">
<h3 data-number="2.1.3" class="anchored" data-anchor-id="distance-based-on-n-grams"><span class="header-section-number">2.1.3</span> Distance based on n-grams</h3>
<p>An <span class="math inline">\(n\)</span>-gram of a string is nothing but a sequence of <span class="math inline">\(n\)</span> characters of that string. E.g. all 2-grams of “books” are “bo”, “oo”, “ok” and “ks”. The 2-grams of “boots” are “bo”, “oo”, “ot” and “ts”.</p>
<p>To calculate the distance based on 2-grams between two words, one looks at all 2-grams occurring in at least one of the words and considers the absolute value of the difference between the number of occurrences in the two words. For the example above this becomes:</p>
<table class="table">
<caption>Table 1: 2-grams and their occurrences in the words “books” and “boots”</caption>
<thead>
<tr class="header">
<th>2-gram</th>
<th style="text-align: center;">books</th>
<th style="text-align: center;">boots</th>
<th style="text-align: center;">difference</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>bo</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>oo</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>ok</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>ks</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td>ot</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>ts</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>Hence, the distance based on 2-grams between “books” and “boots” is 4.</p>
</section>
</section>
<section id="token-based-methods" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="token-based-methods"><span class="header-section-number">2.2</span> Token-based methods</h2>
<p>When words are swapped places in two strings, character-based methods will typically attribute a large distance (or low similarity) to these two strings. Methods based on “tokens” attempt to address this.</p>
<p>We list some token-based methods below:</p>
<ul>
<li>Method based on “atomic strings”. This method will typically work well when certain words are sometimes abbreviated.</li>
<li>A method combining n-grams with “tf.idf”</li>
</ul>
<section id="method-based-on-atomic-strings" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="method-based-on-atomic-strings"><span class="header-section-number">2.2.1</span> Method based on “atomic strings”</h3>
<p>In this context, an “atomic string” refers to a sequence of alphanumeric characters bounded by other characters. We say that two “atomic strings” produce a match when they are equal or when one of them is a prefix of the other. E.g. “Univ” and “University” match because the former is a prefix of the latter.</p>
<p>In this method, the similarity between two strings A and B is defined as the number of atomic strings of A that yield a match to an atomic string of B divided by the average number of atomic strings in strings A and B.</p>
<p>By way of example, suppose that:</p>
<ul>
<li>string A equals “Comput. Sci. &amp; Eng. Dept., University of California, San Diego”</li>
<li>and that string B equals “Department of Computer Science, Univ. Calif., San Diego”</li>
</ul>
<p>The atomic strings of A and B are: - for string A: “Comput”, “Sci”, “Eng”, “Dept”, “University”, “of”, “California”, “San”, “Diego” - for string B: “Department”, “of”, “Computer”, “Science”, “Univ”, “Calif”, “San”, “Diego”</p>
<p>The following atomic strings of A match with an atomic string of B:</p>
<ul>
<li>“Comput” matches with “Computer”</li>
<li>“Sci” matches with “Science”</li>
<li>“University” matches with “Univ”</li>
<li>“of” matches with “of”</li>
<li>“California” matches with “Calif”</li>
<li>“San” matches with “San”</li>
<li>“Diego” matches with “Diego”</li>
</ul>
<p>Consequently, the number of atomic strings of A that match an atomic string of B equals 7. On average, strings A and B have <span class="math inline">\((9 + 8)/2 = 8.5\)</span> atomic strings. Consequently, the similarity, based on this method of atomic strings, between A and B is: <span class="math inline">\(7/8.5 = 0.82\)</span>.</p>
<p>If one were to remove the stop word “of” the similarity would become <span class="math inline">\(6/7.5 = 0.8\)</span>.</p>
</section>
<section id="method-combining-n-grams-with-tf.idf" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="method-combining-n-grams-with-tf.idf"><span class="header-section-number">2.2.2</span> Method combining n-grams with “tf.idf”</h3>
<p>tf.idf, which stands for “term frequency, inverse document frequency” is a number indicating how important a word is to the content of a document compared to a collection of documents. Terms that occur frequently in a document have a high “term frequency”. However, if a term occurs in many documents then it also has a high “document frequency”. To determine the tf.idf of a word in a document, the “term frequency” is divided by the “document frequency”. So one only gets a high “tf.idf” for word in a document if this word occurs frequently in this document and does not occur in many other documents.</p>
<p>As a next step, one can put all terms (words) appearing in all documents in a certain order (e.g.&nbsp;alphabetically). A single document can then be summarised by a (very long) list of numbers, each number being the tf.idf of a given term.</p>
<p>Comparing long lists of numbers (i.e.&nbsp;of vectors) is a problem that has been studied extensively. One of the typical ways of comparing such lists of numbers is the so-called cosine similarity. When two lists of numbers are exactly equal then it gives a value equal to +1, when they are exactly opposite the value is equal to -1. Thus, if one wants to identify similar documents, one looks for documents for which the cosine similarity of their tf.idf lists is “large”.</p>
<p>Within the context of database tables, there are few fields that contain enough different words to calculate the tf.idf in a meaningful way. The trick now is to apply the above procedure to the <span class="math inline">\(n\)</span>-grams of the fields. Hence, to apply this technique to compare two strings (in a column) we also need the contents of all (other) strings in the same column.</p>
</section>
</section>
<section id="phonetic-methods" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="phonetic-methods"><span class="header-section-number">2.3</span> Phonetic Methods</h2>
<p>These methods are typically highly language-dependent. Here, words are compared based on their pronunciation. Words with similar pronunciation are assigned higher similarity.</p>
</section>
<section id="methods-based-on-word-semantics" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="methods-based-on-word-semantics"><span class="header-section-number">2.4</span> Methods Based on Word Semantics</h2>
<p>But what if we compare words that are not syntactically similar at all, but which mean the same thing? For example, the words “Car” and “Automobile” are synonyms of each other, but would have little or no similarity with the methods discussed above. We can determine the similarity of words by comparing their word vectors, or <strong>word embeddings</strong>. Word embeddings can be generated with an algorithm like word2vec: As the name suggests, word2vec represents each individual word with a list of numbers, called a vector. The vectors are carefully constructed so that a simple mathematical function (the cosine equality between the vectors) indicates the degree of semantic similarity between the words represented by those vectors. In essence, a word is transformed into a sequence of some 300 numbers and these sequences of numbers will be very similar when comparing words that have the same meaning.</p>
<p>These methods will work well when the words in a column are common words; when it comes to a specific jargon then the words may not be recognised or the vectors with which they are represented will not necessarily show the right behaviour in terms of similarity.</p>
</section>
</section>
<section id="comparing-records" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Comparing Records</h1>
<p>Applying the previous single-column methods to pairs of records, we get a (large number of) records whose fields are numbers. In this post, we call such a record a <strong>comparison record</strong>. Each field in such a comparison record indicates how similar or different the original values in the corresponding columns are.</p>
<p>For each such comparison record, we now want to indicate whether it is a possible duplicate or not, i.e.&nbsp;whether the original records are duplicates or not. This problem can be tackled in several ways.</p>
<p>On the one hand, there are <strong>supervised methods</strong> where we train a binary classification algorithm to detect the duplicates. The problem with this is that such an algorithm typically requires <em>a large amount of labelled data</em>. This is not very interesting because creating such a labelled dataset requires a large effort.</p>
<p>It is more interesting to recognise duplicates based on an <strong>unsupervised method</strong>, i.e.&nbsp;a method that can work <em>without labelled data</em>. The underlying idea is that the comparison records will look “different” for duplicates compared to “non-duplicates”. Intuitively, we can expect duplicates to have many high similarities, while non-duplicates probably do not.</p>
<p>A first unsupervised method one can try is a (hard) <strong>clustering method</strong> such as the <strong>k-means algorithm</strong>. In this case, we would typically work with 2 classes. After the algorithm has been run, the comparison records will be divided into two classes. We can assume that the smallest class is the class containing the duplicates (since we assume that there are far fewer duplicates than non-duplicates). These can then be presented to the user for verification.</p>
<p>The main disadvantage of hard clustering methods is that they give a yes/no answer and cannot indicate how “certain” they are about their answer. For that, other methods are needed that can indicate the (un)certainty in their answer.</p>
<p>A <strong>Gaussian mixture model</strong> can be seen as a “soft” version of the (hard) k-means clustering algorithm. After running this algorithm, each record has a certain “probability” of belonging to a particular cluster. The mathematical details are relatively complicated but again, we can assume that the “smallest” cluster is the one that represents the duplicates. In this case, we can only show the most “obvious” (candidate) duplicates to the user for verification.</p>
<p>Supervised learning has the problem of requiring a large amount of labelled data; in unsupervised learning this is not the case but here it is also not always clear whether a record (pair) is a duplicate or not. In <strong>active learning</strong>, the algorithm itself searches for record pairs that are most informative (to the algorithm); these will typically be record pairs that are rather “ambiguous”. These records are then shown to the user with a request to label them.</p>
<section id="limiting-the-number-of-record-comparisons" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="limiting-the-number-of-record-comparisons"><span class="header-section-number">3.1</span> Limiting the Number of Record Comparisons</h2>
<p>When running algorithms, it is important that they finish executing within a reasonable time. This is where there can be a catch with duplicate detection. If one has e.g.&nbsp;<span class="math inline">\(1000\)</span> records then the number of pairs is about 500,000! (The exact number is <span class="math inline">\(1000 \times 999 / 2 = 499,500\)</span> but <span class="math inline">\(500,000\)</span> is obviously easier to work with). For a dataset with <span class="math inline">\(10,000\)</span> records, the number of pairs is already about <span class="math inline">\(50,000,000\)</span>! Even for fast and powerful computers, this can quickly become a problem. If one wants to express this technically, one says that the number of pairs is of order <span class="math inline">\(n^2\)</span>, where <span class="math inline">\(n\)</span> represents the number of records.</p>
<p>In certain cases, however, one may have domain knowledge that allows one to deduce that records that differ in a particular column (or in the initial letters of a column value) are most likely not duplicates. One can then use this to dramatically reduce the number of records to be compared.</p>
<p>By way of example, suppose one has a customer list and one has stored the gender of the customer. To keep the example simple, we assume that there are only two possible values, i.e.&nbsp;‘M’ and ‘F’. While it is possible that the gender was noted incorrectly and thus duplicates occur between ‘M’ and ‘F’ this seems unlikely. Now if we assume that there are <span class="math inline">\(1000\)</span> customers of which <span class="math inline">\(500\)</span> are ‘M’ and <span class="math inline">\(500\)</span> are ‘F’, and we compare only <em>within</em> ‘M’ and <em>within</em> ‘F’ then the number of records to be compared is about <span class="math inline">\(125,000\)</span> (for ‘M’) and <span class="math inline">\(125,000\)</span> (for ‘V’). Together this is <span class="math inline">\(250,000\)</span>, and thus about half of what the number of records to compare would be without this division.</p>
<p>If we can partition even more, the gains become even greater. Suppose there is a certain column with <span class="math inline">\(10\)</span> different values that occur <span class="math inline">\(100\)</span> times each (i.e.&nbsp;there are still 1000 records) and it is very unlikely that any two records are duplicates when they have a different value for this column. If, as already mentioned, we assume that each value occurs <span class="math inline">\(100\)</span> times then the number of records to compare is roughly equal to <span class="math inline">\(10 \times 5000\)</span> which is equal to <span class="math inline">\(50,000\)</span>. Compare this with the <span class="math inline">\(500,000\)</span> records we have to compare without this division.</p>
<p>The technical name for this partitioning is <strong>blocking</strong>, and it is a crucial technique for making duplicate detection scalable.</p>
</section>
</section>
<section id="python-libraries-for-duplicate-detection" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Python Libraries for Duplicate Detection</h1>
<p>By now, it should be clear that implementing an algorithm for duplicate detection from scratch will require a fair amount of work. Fortunately, implementations of these various methods are already available in easy-to-use Python libraries. Some examples are:</p>
<ul>
<li><a href="https://docs.dedupe.io/en/latest/">Dedupe.io</a> According to their website, dedupe will help you to:
<ul>
<li>remove duplicates from a spreadsheet of names and addresses</li>
<li>link a list of customer information to order, even if no unique customer ID is present.</li>
</ul></li>
<li><a href="https://www.deduplipy.com/">deduplipy</a> A Python library that uses active learning to detect duplicates and can be used “out-of-the-box” but at the same time allows advanced users to tune the algorithm to their own needs, according to the website.</li>
<li><a href="https://github.com/chu-data-lab/zeroer">zeroER</a> is the implementation that goes with the research paper “ZeroER: Entity Resolution using Zero Labeled Examples” which, as the title indicates, does not require any labelled example to do “entity resolution” (which is another name for duplicate detection). This code is very much of “research quality” and is not supported by a (fancy) website or a finished product.</li>
<li><a href="https://github.com/J535D165/recordlinkage">The Python Record Linkage Toolkit</a> is a library for linking records within or between data sources. According to information on their website, the toolkit offers most of the tools needed for record linkage and deduplication. The package includes indexing methods, record comparison functions and classifiers. The package is designed for research and linking small or medium-sized files. Again according to the information provided by this library, its main features are:
<ul>
<li>Creating pairs of records with smart indexing methods such as blocking and sorted neighbourhood indexing</li>
<li>The toolkit includes various classification algorithms, both supervised and unsupervised.</li>
</ul></li>
</ul>
</section>
<section id="conclusion" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Conclusion</h1>
<p>Duplicate detection is essential for maintaining data accuracy, as they identify records referring to the same entity despite variations. This guide outlined various methods for comparing columns, such as character-based, token-based, phonetic, and semantic approaches. It also explored techniques for comparing entire records using supervised and unsupervised methods. Additionally, the use of blocking reduces computational load by limiting comparisons. Python libraries like Dedupe.io, deduplipy and the Python Record Linkage Toolkit provide practical tools to implement these techniques efficiently, ensuring reliable and actionable data.</p>
<div class="line-block"><em>This blog post is mainly a translation of a blog post written in Dutch. The original blog post can be found <a href="https://ai-assisted-mdm.be/node/32">here</a></em></div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>